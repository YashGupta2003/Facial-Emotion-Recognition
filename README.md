# Facial-Emotion-Recognition
ğŸ­ Facial Emotion Recognition System â€“ AI-Powered Real-Time Analysis
ğŸš€ Developed by: Yash Gupta
ğŸ§  Powered by: TensorFlow | OpenCV | Streamlit

ğŸ”¥ Project Overview
The Facial Emotion Recognition System is an AI-driven solution that detects and classifies human emotions in real-time video streams with an 89% accuracy rate using the FER 2013 dataset. This project integrates self-learning AI capabilities, continuously improving its predictions over time by dynamically collecting and retraining on new data.

ğŸš€ Key Features:
âœ… Real-Time Emotion Detection â€“ Live video analysis for instant recognition.
âœ… Self-Learning AI ğŸ¤– â€“ Automatically captures new emotions & improves over time.
âœ… Dynamic Emotion Representation â€“ Displays detected emotions with names, emojis & scores.
âœ… Live Data Collection & Adaptive Learning â€“ Enhances recognition accuracy with real-world feedback.

âš™ï¸ Technologies Used
ğŸ”¹ TensorFlow, Keras â€“ Deep learning framework for training and model development.
ğŸ”¹ OpenCV â€“ Face detection and image processing.
ğŸ”¹ Streamlit â€“ Interactive web-based user interface.
ğŸ”¹ Haar Cascade Classifier â€“ Face detection model.
ğŸ”¹ NumPy â€“ Data handling and manipulation.

ğŸ›  Model Architecture
The model is built using Convolutional Neural Networks (CNNs), consisting of:
ğŸ”¹ Three Convolutional Layers â€“ Feature extraction using ReLU activation and Max Pooling.
ğŸ”¹ Final Softmax Layer â€“ Multi-class classification for emotions.
ğŸ”¹ Dropout Layers â€“ Prevents overfitting and improves generalization.
ğŸ”¹ Adam Optimizer + Categorical Cross-Entropy Loss â€“ Ensures optimal learning and convergence.

ğŸ“Š Training & Performance
âœ… Dataset Used: FER 2013 (Kaggle)
âœ… Data Preprocessing: Image augmentation, normalization & data balancing
âœ… Train-Test Split: 80% training | 20% validation/testing
âœ… Final Accuracy: ğŸš€ 89% (with Early Stopping & Model Checkpointing)

ğŸ¤¯ Revolutionary Self-Learning Feature
This project goes beyond static emotion detection by incorporating a self-learning mechanism:
âœ… Captures new user emotions in real-time ğŸ“·
âœ… Automatically stores new faces & expressions ğŸ§ 
âœ… Retrains itself continuously for improved accuracy ğŸ“ˆ
âœ… Adapts to different user emotions & cultural variations ğŸŒ
âœ… Enhances future recognition through feedback loops ğŸ”„

ğŸ“Š Dynamic Emotion Scoring System
Each detected emotion is assigned a score (0-5) to quantify its intensity:
ğŸ˜Š Happy â€“ Score: 5/5
ğŸ˜ Sad â€“ Score: 1/5
ğŸ˜  Angry â€“ Score: 1/5
ğŸ˜ Neutral â€“ Score: 3/5
ğŸ˜® Surprised â€“ Score: 4/5

This scoring system enables AI-driven decision-making for mental health monitoring, customer feedback analysis, and behavioral studies.

ğŸš€ Future Enhancements
ğŸ”¹ Multi-user emotion detection â€“ Analyze emotions for multiple users simultaneously.
ğŸ”¹ Voice emotion integration â€“ Expand detection to speech-based emotions.
ğŸ”¹ Mental health monitoring â€“ AI-driven mood tracking for therapeutic insights.
ğŸ”¹ AI-powered customer feedback analysis â€“ Emotion-based market research.

This AI is evolving, learning, and redefining real-time human interaction! ğŸŒ

ğŸ¯ Contribution & Support
Contributions are welcome! If you're passionate about AI & Deep Learning, feel free to fork, improve, and contribute!

ğŸ“© For inquiries, collaboration, or enhancements, reach out to me on LinkedIn

Give this project a â­ if you find it useful!


